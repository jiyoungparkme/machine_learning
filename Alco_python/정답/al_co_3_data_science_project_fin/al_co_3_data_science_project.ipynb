{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Project Life-Cycle\n",
    "##### 1. Domain Understanding - 대상 분야 이해\n",
    "##### 2. Data Understanding - 데이터 이해하기\n",
    "##### 3. Data Exploration - 데이터 탐색\n",
    "##### 4. Data Preparation - 데이터 준비\n",
    "##### 5. Model Planning - 모델 기획\n",
    "##### 6. Model Building - 모델 수립\n",
    "##### 7. Communicate Results - 결과 토의\n",
    "##### 8. Operationalize - 사내 시스템 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비 단계\n",
    "* 모델링 알고리즘에 집어넣기 위해 데이터 셋을 준비하는 단계\n",
    "* 학습 / 평가용으로 데이터 셋 분리 -> row 분리\n",
    "* feature / label 분리 -> column 분리\n",
    "* A가 B에 영향을 주나? 또는 상관/연관이 있나? 라는 문장이 있다면\n",
    "* 각 컬럼은 A 또는 B에 들어갑니다.\n",
    "* A로 B 설명 가능?\n",
    "* A에 들어가는 컬럼들을 Feature 라 합니다.\n",
    "* B에 들어가는 컬럼을 Label 이라 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('processed.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
    "       'humidity', 'windspeed', 'year','month', 'day', 'hour', 'dayofweek']\n",
    "label = 'count'\n",
    "# label 은 알고리즘에서 맞추고자 하는 대상입니다.\n",
    "# 따라서 feature 들로 label을 맞추고자 하는 것입니다.\n",
    "# 날짜와 날씨 정보를 이용해 자전거 수요량을 알아맞추고자 합니다.\n",
    "X, y = df[features], df[label]\n",
    "# f(X) -> y\n",
    "# f? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습의 분야\n",
    "* 지도학습(supervised learning)\n",
    "* 수치를 맞추는 경우(회귀, regression), 경우의 수를 맞추는 경우(분류, classification)\n",
    "* 비지도학습(unsupervised learning)\n",
    "* 알고리즘이 데이터 안의 패턴을 스스로 찾아내게 만드는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as dt\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gb\n",
    "model = dt()\n",
    "# regressor 라는 것은 label(맞추고자 하는 값)이 수치인 경우\n",
    "# 다음 주에 다룰 classifier 는 label이 경우의 수입니다.\n",
    "model.fit(X, y) # 공부\n",
    "# fit 이라는 것은 공부(학습)를 하는 것입니다.\n",
    "# X에 들어있는 날짜, 날씨 정보 이용해 y에 있는 수요량을 맞추게끔\n",
    "# 학습을 진행합니다.\n",
    "model.score(X, y) # 시험\n",
    "# 잘 맞췄는지 못 맞췄는지 평가하려면 숫자이기 때문에 \n",
    "# 예측한 숫자가 원래 숫자와 얼마나 가까운가? 로 판단합니다.\n",
    "# R2(R-squared) 라고 하는 평가 지표입니다.(점수 산정 방식)\n",
    "# R2 의 특징은 보통 0 ~ 1 사이의 값을 갖고, 1에 가까울수록 예측을 잘 한 것입니다.\n",
    "# 가끔씩 - 값을 갖는 경우도 있는데, 예측을 아주 못 했다고 보시면 되겠습니다.\n",
    "# .fit에서 공부한 데이터와 .score로 시험 본 데이터는 같은 데이터입니다.\n",
    "# 이러면 학습이 제대로 되지 않았다고 해도 고득점이 가능할 것입니다.\n",
    "# 공부할 문제와 시험 볼 문제를 나누어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "for_plot = pd.DataFrame()\n",
    "for_plot['predict'] = model.predict(X)\n",
    "for_plot['actual'] = y\n",
    "sns.scatterplot(data=for_plot, x='actual', y='predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df[0::2], df[1::2]\n",
    "# 홀 / 짝 기준으로 학습용과 시험용 데이터 셋을 분할하였습니다.\n",
    "train, test = train.reset_index(), test.reset_index()\n",
    "# 인덱스(순서)를 다시 매겨주기 위해서 reset_index() 이용하였습니다.\n",
    "X_train, y_train = train[features], train[label]\n",
    "X_test, y_test = test[features], test[label]\n",
    "# X, y 나눈것과 동일하게 feature 와 label 로 문제 부분과 정답 부분을 나누어 줍니다.\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt, rf, gb\n",
    "model = rf()\n",
    "model.fit(X_train, y_train) # 공부용 문제집과 공부용 정답지 주고 공부 시작\n",
    "model.score(X_test, y_test) # 시험용 문제집과 시험용 정답지 주고 시험 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "for_plot = pd.DataFrame()\n",
    "for_plot['predict'] = model.predict(X_test)\n",
    "for_plot['actual'] = y_test\n",
    "sns.scatterplot(data=for_plot, x='actual', y='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature selection - 변수 선택법\n",
    "* 알고리즘에 집어넣을 변수를 선택하는 방법\n",
    "* 알고리즘에 넣을 변수는 정확도가 유사하다면 변수 개수가 적을수록 좋습니다.\n",
    "* 1. 단변량 - filter -> 컬럼 하나 정해서 한 컬럼이 의미가 있나 보는 것(기초통계)\n",
    "* 2. 전진/후진 선택법 - wrapper -> 하나씩 넣으며 점수 확인, 하나씩 빼며 점수 확인\n",
    "* 3. 임베드 - embed -> 알고리즘의 성질 이용(알고리즘 내부를 뜯어볼 수 있는 경우)\n",
    "* 4. SHAP, permutaion importance\n",
    "* ---알코반에서는 다루지 않음, 원래는 이 용도로 만들어진 것이 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf()\n",
    "model.fit(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "train_score = model.score(X_train, y_train)\n",
    "print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### filter method\n",
    "* 한 컬럼만 딱 정해서 통계량을 뽑는 것입니다.\n",
    "* 예) 표준편차가 0에 가깝다? 또는 다른 feature들과 상관관계가 너무 높다?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['for_filter'] = 1\n",
    "df.describe().T.sort_values('std')['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x='temp', y='atemp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()\n",
    "# df.corr() 이용하면 각 컬럼간 상관계수가 들어있는\n",
    "# 상관계수행렬 이라고 하는 정보가 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax1 = plt.subplots()\n",
    "fig.set_size_inches(16, 8)\n",
    "sns.heatmap(df.corr(), ax=ax1)\n",
    "# 이를 숫자 대신 그래프로 보기 위해 heatmap 방식을 이용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### filter 방식으로 변수 선택한 결과\n",
    "* temp, atemp 사이에 상관계수가 높았기 때문에 둘 중 하나를 제거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['season', 'holiday', 'workingday', 'weather', 'temp', 'humidity', \n",
    "            'windspeed', 'year', 'month', 'day', 'hour', 'dayofweek']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wrapper - 전진 / 후진 선택\n",
    "* feature에 변수를 추가 / 제거하면 모델의 성능이 달라질 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split(df, features, label):\n",
    "    # 데이터 셋, feature 대상, label 을 넣었을 때\n",
    "    # 데이터 셋 분할을 해 주는 함수를 만들어주었습니다.\n",
    "    train, test = df[0::2], df[1::2]\n",
    "    train, test = train.reset_index(), test.reset_index()\n",
    "    X_train, y_train = train[features], train[label]\n",
    "    X_test, y_test = test[features], test[label]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features = ['temp', 'holiday', 'temp']\n",
    "X_train, y_train, X_test, y_test = df_split(df, sample_features, 'count')\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations as co\n",
    "sample_bag = [1, 2, 3]\n",
    "for c in co(sample_bag, 2):\n",
    "    # co(sample_bag, 2) 는 sample_bag 으로부터 2개를 뽑는 경우의 수 입니다.\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 전진 선택법(Forward 방식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result = []\n",
    "for c in co(features, 2):\n",
    "    # co(features, 2) 는 features 으로부터 2개를 뽑는 경우의 수 입니다.\n",
    "    X_train, y_train, X_test, y_test = df_split(df, list(c), 'count')\n",
    "    # features 로부터 2개씩 뽑고, 이를 이용해 feature로 사용합니다.\n",
    "    # 그러면 예측에 필요한 재료가 달라진 데이터 셋이 완성되게 됩니다.\n",
    "    model = rf()\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    sub_result = {'combination' : str(c), 'score' : score}\n",
    "    # 이 조합일 때 이 점수였다는 정보를 딕셔너리로 만들어줍니다.\n",
    "    all_result.append(sub_result)\n",
    "    # 한 번 반복시마다 한 조합과 그 조합의 점수가 나오게 됩니다.\n",
    "    # 이를 리스트에 차곡차곡 쌓았습니다.\n",
    "result_df = pd.DataFrame(all_result).sort_values(by='score')\n",
    "# 같은 키를 공유하는 딕셔너리들이 리스트에 들어있으면\n",
    "# 이를 이용해 데이터 프레임을 만들어낼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_candidate = ['season', 'holiday', 'weather', 'temp', 'humidity',\n",
    "                      'windspeed', 'year', 'month', 'day', 'dayofweek']\n",
    "# 가장 점수가 잘 나왔던 조합인 ['workingday', 'hour'] 를 제외하고\n",
    "# 하나 추가할 feature의 후보군을 추리기 위해 feature_cand 를 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in feature_candidate:\n",
    "    good_features = ['workingday', 'hour']\n",
    "    good_features.append(c)\n",
    "    X_train, y_train, X_test, y_test = df_split(df, good_features, 'count')\n",
    "    model = rf()\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    sub_result = {'combination' : str(good_features), 'score' : score}\n",
    "    all_result.append(sub_result)\n",
    "result_df = pd.DataFrame(all_result).sort_values(by='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_candidate = ['season', 'holiday', 'weather', 'temp', 'humidity',\n",
    "                      'windspeed', 'month', 'day', 'dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in feature_candidate:\n",
    "    good_features = ['workingday', 'hour', 'year']\n",
    "    good_features.append(c)\n",
    "    X_train, y_train, X_test, y_test = df_split(df, good_features, 'count')\n",
    "    model = rf()\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    sub_result = {'combination' : str(good_features), 'score' : score}\n",
    "    all_result.append(sub_result)\n",
    "result_df = pd.DataFrame(all_result).sort_values(by='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 후진 제거(Backward 방식)\n",
    "* 하나씩 제거하는 방식\n",
    "* 전체 feature를 다 집어넣은 상태에서 시작\n",
    "* 하나씩 빼 가면서 점수를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result = []\n",
    "for item in co(features, len(features)-1):\n",
    "    target = list(item)\n",
    "    X_train, y_train, X_test, y_test = df_split(df, target, 'count')\n",
    "    model = rf()\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    dropped = str(set(features) - set(target))\n",
    "    sub_result = {'dropped' : dropped, 'score' : score}\n",
    "    all_result.append(sub_result)\n",
    "result_df = pd.DataFrame(all_result).sort_values(by='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "# recursive feature ellimination\n",
    "# 직접 구현하지 안아도 sklearn에서 이미 도구로 구현되어있음\n",
    "rfe = RFE(estimator=model)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "for_rfe = pd.DataFrame()\n",
    "for_rfe['ranking'] = rfe.ranking_\n",
    "for_rfe['features'] = X_train.columns\n",
    "for_rfe.sort_values(by='ranking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### embed - 임베드 방식, 알고리즘 내부를 뜯어볼 수 있는 경우.\n",
    "* 내부에서 각 feature 구성요소들이 얼마나 사용되었는지를 알아보는 방식\n",
    "* 알고리즘 중에서는 내부에 변수의 중요도를 내포하고 있는 것들이 있습니다.\n",
    "* 이러한 알고리즘들을 이용해 변수의 중요도를 파악, 중요도 낮은 것을 지울 수 있습니다.\n",
    "* Tree 계열, Regularizer 가 있는 경우\n",
    "* Random Forest, Decision Tree 등이 Tree 계열\n",
    "* L1(lasso), L2(ridge) regularizer 가 있는 경우. L1 많이 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf()\n",
    "model.fit(X_train, y_train)\n",
    "model.feature_importances_\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame()\n",
    "scores['feature'] = X_train.columns\n",
    "scores['importance'] = model.feature_importances_\n",
    "scores = scores.sort_values(by='importance')\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle 따라잡기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10886, 12)\n",
      "(6493, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimer = train['datetime'].apply(lambda x : pd.to_datetime(x))\n",
    "train['year'] = datetimer.apply(lambda x : x.year)\n",
    "train['month'] = datetimer.apply(lambda x : x.month)\n",
    "train['hour'] = datetimer.apply(lambda x : x.hour)\n",
    "train['dayofweek'] = datetimer.apply(lambda x : x.dayofweek)\n",
    "\n",
    "datetimer = test['datetime'].apply(lambda x : pd.to_datetime(x))\n",
    "test['year'] = datetimer.apply(lambda x : x.year)\n",
    "test['month'] = datetimer.apply(lambda x : x.month)\n",
    "test['hour'] = datetimer.apply(lambda x : x.hour)\n",
    "test['dayofweek'] = datetimer.apply(lambda x : x.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
       "       'humidity', 'windspeed', 'year', 'month', 'hour', 'dayofweek'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation 단계\n",
    "features = ['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
    "       'humidity', 'windspeed', 'year', 'month', 'hour', 'dayofweek']\n",
    "label = 'count'\n",
    "X_train, y_train = train[features], train[label]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling 단계\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "model = rf()\n",
    "model.fit(X_train, y_train)\n",
    "test['count'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested = ['datetime', 'count']\n",
    "test[interested].to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
